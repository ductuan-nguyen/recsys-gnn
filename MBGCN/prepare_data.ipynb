{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "155906c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc58699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      14,       28,       70, ..., 23245750, 23442668, 23443916])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relevant_clients = np.load('recsys-data/input/relevant_clients.npy')\n",
    "relevant_clients = np.load('/home/tuannd/recsys2025/embed-dir/client_ids.npy')\n",
    "relevant_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800f57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_clients = list(relevant_clients)\n",
    "client_to_id = {int(client): i for i, client in enumerate(relevant_clients)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b1fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open('/home/tuannd/MBGCN/ubc/client_id_to_index.json', 'w') as f:\n",
    "    json.dump(client_to_id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc68832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1197634"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_product = pd.read_parquet('recsys-data/product_properties.parquet')\n",
    "len(df_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "749b946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_sku_to_id = {int(sku): i for i, sku in enumerate(df_product['sku'].values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fee605c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   client_id           timestamp     sku\n",
       " 0   17649961 2022-07-23 20:15:25   18485\n",
       " 1   16696114 2022-07-11 16:31:30   81192\n",
       " 2   10238779 2022-05-29 19:35:40  510014\n",
       " 3   10238779 2022-05-29 19:38:05  510014\n",
       " 4   10238779 2022-05-29 19:38:05  510014,\n",
       " 1315061)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_buy = pd.read_parquet('recsys-data/input/product_buy.parquet')\n",
    "df_buy.head(), len(df_buy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5668c776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "939835"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_buy = df_buy[df_buy['client_id'].isin(relevant_clients)]\n",
    "len(df_buy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd06e7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758720"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ignore timestamps, remove duplicates \n",
    "df_buy = df_buy[['client_id', 'sku']].drop_duplicates()\n",
    "len(df_buy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b34b5a",
   "metadata": {},
   "source": [
    "buy.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19810b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ubc/buy.txt', 'w') as f:\n",
    "    for client_id, sku in df_buy[['client_id', 'sku']].values:\n",
    "        client_id = client_to_id[int(client_id)]\n",
    "        sku = product_sku_to_id[int(sku)]\n",
    "        f.write(f\"{client_id} {sku}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08cf67b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   client_id           timestamp      sku\n",
       " 0   17649961 2022-08-11 12:22:55  1398840\n",
       " 1     315805 2022-09-11 05:34:10  1434568\n",
       " 2   16696114 2022-07-11 16:27:00    81192\n",
       " 3    6297287 2022-06-14 15:52:30  1070234\n",
       " 4   14462111 2022-07-14 12:52:50  1428777,\n",
       " 3959157)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cart = pd.read_parquet('recsys-data/input/add_to_cart.parquet')\n",
    "df_cart.head(), len(df_cart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c701a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1922253"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cart = df_cart[df_cart['client_id'].isin(relevant_clients)]\n",
    "len(df_cart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d291be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1428745"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cart = df_cart[['client_id', 'sku']].drop_duplicates()\n",
    "len(df_cart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9269e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ubc/cart.txt', 'w') as f:\n",
    "    for client_id, sku in df_buy[['client_id', 'sku']].values:\n",
    "        client_id = client_to_id[int(client_id)]\n",
    "        sku = product_sku_to_id[int(sku)]\n",
    "        f.write(f\"{client_id} {sku}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c1d093a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   client_id           timestamp      sku  category  price  \\\n",
       " 0   20673586 2022-09-15 07:08:15  1121365      2027     82   \n",
       " 1    7663245 2022-09-16 16:20:55   541046      4981     57   \n",
       " 2   23379942 2022-09-15 08:00:45   343231      6214     23   \n",
       " 3   23379942 2022-09-15 08:00:45  1404198       335     29   \n",
       " 4     778845 2022-09-25 06:14:20   769663      2882     49   \n",
       " \n",
       "                                                 name  \n",
       " 0  [208 227 135  59  56  16  14 208 135 135 135 1...  \n",
       " 1  [ 38  61 112 239 236 139  59 250 226 142 142  ...  \n",
       " 2  [ 44 226 110   8 104 104  17  20  81  20  50 1...  \n",
       " 3  [ 98 104 104 198 104 237 140  78  98  98 194  ...  \n",
       " 4  [ 58 132 229  63 231 222  25 127 132  71 238  ...  ,\n",
       " 173646)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_parquet('/home/tuannd/MBGCN/recsys-data/target/train_target.parquet')\n",
    "df_train.head(), len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d46c68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73493"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[df_train['client_id'].isin(relevant_clients)]\n",
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccae5f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64240"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.drop_duplicates(subset=['client_id', 'sku'])\n",
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f603da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ubc/validation.txt', 'w') as f:\n",
    "    for client_id, sku in df_train[['client_id', 'sku']].values:\n",
    "        client_id = client_to_id[int(client_id)]\n",
    "        sku = product_sku_to_id[int(sku)]\n",
    "        f.write(f\"{client_id} {sku}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4b55a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   client_id           timestamp      sku\n",
       " 0   23390068 2022-07-03 21:37:25   364528\n",
       " 1    6220048 2022-08-03 10:20:50    98227\n",
       " 2    7621267 2022-06-16 16:24:35  1455655\n",
       " 3   20041561 2022-08-31 09:25:55   967683\n",
       " 4   11590800 2022-08-31 11:18:45   669874,\n",
       " 1230871)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df_remove = pd.read_parquet('recsys-data/input/remove_from_cart.parquet')\n",
    "df_remove.head(), len(df_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86b0b40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800359"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_remove = df_remove[df_remove['client_id'].isin(relevant_clients)]\n",
    "len(df_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a95649c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652920"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_remove = df_remove.drop_duplicates(subset=['client_id', 'sku'])\n",
    "len(df_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d595692",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ubc/remove.txt', 'w') as f:\n",
    "    for client_id, sku in df_remove[['client_id', 'sku']].values:\n",
    "        client_id = client_to_id[int(client_id)]\n",
    "        sku = product_sku_to_id[int(sku)]\n",
    "        f.write(f\"{client_id} {sku}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7bac235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   client_id           timestamp      sku  category  price  \\\n",
       " 0   10238779 2022-10-05 14:41:10  1475246      3068     17   \n",
       " 1   12906549 2022-10-10 11:01:40  1243167      3452     39   \n",
       " 2   17768645 2022-09-29 02:41:55  1201694      1081     27   \n",
       " 3   17768645 2022-09-29 02:41:55   799643      1081     48   \n",
       " 4   17768645 2022-09-29 02:41:55   915239      1081     22   \n",
       " \n",
       "                                                 name  \n",
       " 0  [115 117 115 115 234 115  83  69 224 115 115 1...  \n",
       " 1  [ 76 160  13  13 251 147  77 110 162  90  76  ...  \n",
       " 2  [217 217 217 217 217 217 217 217 217 217 217 2...  \n",
       " 3  [217 217 217 217 217 217 240 217 217 160 217 2...  \n",
       " 4  [217 217 217 217 217 217 217 217 217 217 217 2...  ,\n",
       " 193589)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_parquet('/home/tuannd/MBGCN/recsys-data/target/validation_target.parquet')\n",
    "df_test.head(), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26e26aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77529"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test[df_test['client_id'].isin(relevant_clients)]\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "819be9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61335"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.drop_duplicates(subset=['client_id', 'sku'])\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5412d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ubc/test.txt', 'w') as f:\n",
    "    for client_id, sku in df_test[['client_id', 'sku']].values:\n",
    "        client_id = client_to_id[int(client_id)]\n",
    "        sku = product_sku_to_id[int(sku)]\n",
    "        f.write(f\"{client_id} {sku}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16d25029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(858489, 1197634)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relevant_clients), len(product_sku_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d854a2",
   "metadata": {},
   "source": [
    "### Create .pth file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88b698c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "759808"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2048*371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e8e508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3661401/69232220.py:33: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  indices = torch.tensor([row, col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[     0, 299534, 297718,  ...,   2060, 416268,  44390],\n",
      "                       [     0,      1,      1,  ..., 416267, 416268, 416268]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "       size=(1197634, 1197634), nnz=15720369, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[     0, 299534, 297718,  ...,   2060, 416268,  44390],\n",
      "                       [     0,      1,      1,  ..., 416267, 416268, 416268]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "       size=(1197634, 1197634), nnz=15720369, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[470448, 433314, 400518,  ...,  67817,  15702, 667210],\n",
      "                       [     5,      5,      5,  ..., 667209, 667209, 667210]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "       size=(1197634, 1197634), nnz=7870762, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "import torch  \n",
    "import numpy as np  \n",
    "import scipy.sparse as sp  \n",
    "\n",
    "# Define constants\n",
    "num_users = 858489\n",
    "num_items = 1197634\n",
    "\n",
    "def create_item_similarity_matrix(behavior_file, num_items):  \n",
    "    # Load user-item interactions into a sparse matrix\n",
    "    user_item_matrix = sp.lil_matrix((num_users, num_items))  \n",
    "    with open(behavior_file, 'r') as f:  \n",
    "        for line in f:  \n",
    "            user, item = map(int, line.strip().split())  \n",
    "            user_item_matrix[user, item] = 1.0  \n",
    "\n",
    "    # Convert to CSR format for efficient operations\n",
    "    user_item_matrix = user_item_matrix.tocsr()  \n",
    "\n",
    "    # Compute item-user matrix (transpose)\n",
    "    item_user_matrix = user_item_matrix.T.tocsr()  \n",
    "\n",
    "    # Compute sparse matrix of common users between items\n",
    "    common_users_matrix = item_user_matrix.T @ item_user_matrix  \n",
    "\n",
    "    # Convert to COO format and create binary similarity matrix\n",
    "    coo = common_users_matrix.tocoo()  \n",
    "    row = coo.row  \n",
    "    col = coo.col  \n",
    "    values = np.ones_like(row, dtype=np.float32)  \n",
    "\n",
    "    # Create PyTorch sparse tensor\n",
    "    indices = torch.tensor([row, col])  \n",
    "    values = torch.tensor(values)  \n",
    "    similarity_tensor = torch.sparse_coo_tensor(indices, values, size=(num_items, num_items))  \n",
    "\n",
    "    return similarity_tensor  \n",
    "\n",
    "# Create and save similarity matrices for each behavior\n",
    "# behaviors = ['buy', 'cart']\n",
    "behaviors = ['buy', 'cart', 'remove']\n",
    "for behavior in behaviors:  \n",
    "    similarity_matrix = create_item_similarity_matrix(f'ubc/{behavior}.txt', num_items) \n",
    "    print(similarity_matrix)\n",
    "    torch.save(similarity_matrix, f'ubc/item_{behavior}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_similarity_matrix(behavior_file, num_users):  \n",
    "    # Load user-item interactions into a sparse matrix\n",
    "    user_item_matrix = sp.lil_matrix((num_users, num_items))  \n",
    "    with open(behavior_file, 'r') as f:  \n",
    "        for line in f:  \n",
    "            user, item = map(int, line.strip().split())  \n",
    "            user_item_matrix[user, item] = 1.0  \n",
    "\n",
    "    # Convert to CSR format for efficient operations\n",
    "    user_item_matrix = user_item_matrix.tocsr()  \n",
    "\n",
    "    # Compute user-user similarity matrix\n",
    "    user_similarity_matrix = user_item_matrix @ user_item_matrix.T  \n",
    "\n",
    "    # Convert to COO format and create binary similarity matrix\n",
    "    coo = user_similarity_matrix.tocoo()  \n",
    "    row = coo.row  \n",
    "    col = coo.col  \n",
    "    values = np.ones_like(row, dtype=np.float32)  \n",
    "\n",
    "    # Create PyTorch sparse tensor\n",
    "    indices = torch.tensor([row, col])  \n",
    "    values = torch.tensor(values)  \n",
    "    similarity_tensor = torch.sparse_coo_tensor(indices, values, size=(num_users, num_users))  \n",
    "\n",
    "    return similarity_tensor\n",
    "\n",
    "# Create and save user similarity matrix\n",
    "behaviors = ['buy', 'cart', 'remove']\n",
    "for behavior in behaviors:  \n",
    "    similarity_matrix = create_user_similarity_matrix(f'ubc/{behavior}.txt', num_users) \n",
    "    print(similarity_matrix)\n",
    "    torch.save(similarity_matrix, f'ubc/user_{behavior}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac91c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relation_rebuild = torch.load('ubc/item_buy.pth')\n",
    "# print(relation_rebuild.shape)\n",
    "# relation_rebuild.sum(dim=1).float().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874339cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# sku_target = np.load('/home/tuannd/MBGCN/recsys-data/target/propensity_sku.npy')\n",
    "# sku_target\n",
    "\n",
    "# sku_target_id = [product_sku_to_id[int(sku)] for sku in sku_target]\n",
    "# with open('Recsys2025/target_sku.txt', 'w') as f:\n",
    "#     for sku_id in sku_target_id:\n",
    "#         f.write(f\"{sku_id}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773d93fc",
   "metadata": {},
   "source": [
    "### User => query => item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72b2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_query = pd.read_parquet('recsys-data/search_query.parquet')\n",
    "df_query.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query.drop_duplicates(subset=['client_id', 'query'], inplace=True)\n",
    "len(df_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc0052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product = pd.read_parquet('recsys-data/product_properties.parquet')\n",
    "df_product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f294577",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304803fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Set up FAISS index\n",
    "dimension = 16  # Embedding dimension\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner product (similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a1b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product embeddings\n",
    "# convert this string to numpy array\n",
    "# [167  24 193  24  24  92 167  76  29  45 172 203  24 172 232  32]\n",
    "product_embeddings = df_product['name'].apply(lambda x: np.fromstring(x[1:-1], sep=' ')).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235a2e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "product_embeddings = np.array(product_embeddings, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb9f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_embeddings\n",
    "# normalize the embeddings\n",
    "product_embeddings /= np.linalg.norm(product_embeddings, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513d57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Use GPU if available\n",
    "res = faiss.StandardGpuResources()\n",
    "gpu_index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "\n",
    "# Add product embeddings (ensure float32 for FAISS)\n",
    "gpu_index.add(product_embeddings)  # Use index.add() for CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e920d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embeddings = df_query['query'].apply(lambda x: np.fromstring(x[1:-1], sep=' ')).tolist()\n",
    "query_embeddings = np.array(query_embeddings, dtype=np.float32)\n",
    "# normalize the query embeddings\n",
    "query_embeddings /= np.linalg.norm(query_embeddings, axis=1, keepdims=True)\n",
    "query_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763633db",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ids = df_product['sku'].values\n",
    "client_ids = df_query['client_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Set your desired top-k value\n",
    "k = 5  # Example: top 5 similar products\n",
    "\n",
    "# Step 2: Search for top-k similar products in batches\n",
    "batch_size = 100000  # Adjust based on memory\n",
    "all_product_indices = []\n",
    "\n",
    "for start in tqdm(range(0, len(query_embeddings), batch_size)):\n",
    "    end = min(start + batch_size, len(query_embeddings))\n",
    "    batch = query_embeddings[start:end].astype(np.float32)\n",
    "    distances, indices = gpu_index.search(batch, k=k)  # k > 1 for top-k matches\n",
    "    all_product_indices.extend(indices.tolist())  # Each element is a list of top-k indices\n",
    "\n",
    "# Step 3: Map indices to product IDs\n",
    "all_mapped_product_ids = [[product_ids[idx] for idx in top_k] for top_k in all_product_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1211ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_mapped_product_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2433573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_pairs = []\n",
    "for client_id, query_products in zip(client_ids, all_mapped_product_ids):\n",
    "    for product_id in query_products:\n",
    "        query_pairs.append((client_id, product_id))\n",
    "\n",
    "query_pairs = set(query_pairs)  # Remove duplicates\n",
    "len(query_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buy = pd.read_parquet('recsys-data/product_buy.parquet')\n",
    "df_buy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many pair of client_id and sku from query_to_product_mapping.csv is in df_buy\n",
    "df_buy = df_buy.drop_duplicates(subset=['client_id', 'sku'])\n",
    "buy_pairs = set(zip(df_buy['client_id'], df_buy['sku']))\n",
    "\n",
    "# query_pairs = set(zip(df['client_id'], df['product_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ce7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(buy_pairs), len(query_pairs), len(buy_pairs & query_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56de9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add = pd.read_parquet('recsys-data/add_to_cart.parquet')\n",
    "df_add.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af816491",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add = df_add.drop_duplicates(subset=['client_id', 'sku'])\n",
    "add_pairs = set(zip(df_add['client_id'], df_add['sku']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ed483",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(add_pairs), len(query_pairs & add_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0bcf44",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "client_ids_mbgcn = np.load('/home/tuannd/MBGCN/submits/exp_item_feature_3/client_ids.npy')\n",
    "client_ids_mbgcn = list(client_ids_mbgcn)\n",
    "embedding_mbgcn = np.load('/home/tuannd/MBGCN/submits/exp_item_feature_3/embeddings.npy')\n",
    "embedding_mbgcn.shape\n",
    "\n",
    "embedding_baseline = np.load('/home/tuannd/recsys2025/embed-dir/embeddings.npy') \n",
    "embedding_baseline.shape\n",
    "\n",
    "client_ids = np.load('/home/tuannd/recsys2025/embed-dir/client_ids.npy')\n",
    "client_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d267beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a dictionary for O(1) lookups of client_id to index in client_ids_mbgcn\n",
    "client_id_to_idx = {cid: idx for idx, cid in enumerate(client_ids_mbgcn)}\n",
    "\n",
    "# Initialize the output array\n",
    "embedding_new = np.zeros((len(client_ids), embedding_mbgcn.shape[1] + embedding_baseline.shape[1]), dtype=np.float32)\n",
    "\n",
    "# Create index arrays for vectorized assignment\n",
    "valid_indices = []\n",
    "mbgcn_indices = []\n",
    "for i, client_id in enumerate(client_ids):\n",
    "    if client_id in client_id_to_idx:\n",
    "        valid_indices.append(i)\n",
    "        mbgcn_indices.append(client_id_to_idx[client_id])\n",
    "\n",
    "# Vectorized assignment for mbgcn embeddings\n",
    "if valid_indices:\n",
    "    embedding_new[valid_indices, :embedding_mbgcn.shape[1]] = embedding_mbgcn[mbgcn_indices]\n",
    "\n",
    "# Vectorized assignment for baseline embeddings\n",
    "embedding_new[:, embedding_mbgcn.shape[1]:] = embedding_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46884e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e9671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the new embeddings\n",
    "# embedding_new /= np.linalg.norm(embedding_new, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c126a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/tuannd/MBGCN/submits/exp_item_feature_4/embeddings.npy', embedding_new.astype(np.float16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
